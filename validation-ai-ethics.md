---
layout: default
---

<h1 class="cards-page-title">Validation of AI Ethics</h1>

<div class="paragraph">
<p>
The AI ethics assessment in FAIRiCUBE ensures that artificial intelligence is used responsibly and transparently across all Use Cases. The assessment examines how AI models are developed, how transparent their processes are, and whether they avoid bias or unfair outcomes. It also provides practical guidance to ensure that AI is implemented ethically throughout the project and reports on the validation results in a structured and traceable way. 


 <table>
  <tr>
    <td>Validation item</td>
    <td>Description </td>
  </tr>
  <tr>
    <th>Ethics (Trustworthy AI)</th>
  </tr>

  <tr>
    <td>Fundamental rights</td>
    <td>How are you dealing with the effect of the application on the rights to safety, health, non-discrimination, and freedom of association?</td>
  </tr>
  <tr>
    <td>Privacy and data protection</td>
    <td>How are you implementing the GDPR to safeguard the personal data protection rights of those you collect personal data from?</td>
  </tr>
  <tr>
    <td>Transparency rights</td>
    <td>Do you include the following user rights to:
be notified that their data is being processed/collected,
access information on which personal data are collected,
control their data,
access explanations of results produced by the system,
be informed of who, when and how the system can be audited.
</td>
  </tr>
  <tr>
    <td>Accessibility</td>
    <td>Can your app/system/resource be used by all regardless of demographics, language, disability, digital literacy, and financial accessibility?</td>
  </tr>
  <tr>
    <td>Education and tutorials</td>
    <td>Do you ensure that users are informed and capable of using the system correctly?</td>
  </tr>
  <tr>
    <td>Data management</td>
    <td>Do you comply with the data-minimization principle, i.e. usage of local and temporary storage and encryption, based on principles of data protection by design? Do you ensure that only strictly necessary data are captured and processed?</td>
  </tr>
  <tr>
    <td>Security</td>
    <td>Do you have user authentication in place to prevent risks such as access, modification, or disclosure of the data? Do you use unique and pseudo-random identifiers, renewed regularly and cryptographically strong?</td>
  </tr>
  <tr>
    <td>Ease to deactivate/remove</td>
    <td>How easy is it to deactivate or remove the system and data once users are no longer interested or need the system?</td>
  </tr>
  <tr>
    <td>Ease to access services without using the AI system</td>
    <td>In the case of AI systems aimed to replace or complement (public) services, are there full non-system alternatives?</td>
  </tr>
  <tr>
    <td>Open-source code </td>
    <td>Is the development participatory and multidisciplinary? What kind of access to the code and development is there?</td>
  </tr>
  <tr>
    <td>Ownership</td>
    <td>Is the ownership of the resource clear?</td>
  </tr>
  <tr>
    <td>Openness about Data governance</td>
    <td>How open is Data governance? Do you have a policy and actions to share data under an open data license?</td>
  </tr>
  <tr>
    <td>Legislation and Policy</td>
    <td>Are there explicit legislation and/or other policies relevant to your system/resource?</td>
  </tr>
  <tr>
    <td>Design Impact Assessment and Open Development Process</td>
    <td>How publicly accessible is the information about the design process leading to this resource?</td>
  </tr>
 <tr>
    <td>Right to contest/liability</td>
    <td>How are users able to contest decisions/actions or demand human intervention?</td>
  </tr>

  <tr>
    <th>GDPR applicability</th>
  </tr>

  <tr>
    <td>List of data</td>
    <td>List the types of data you will process in your pilot</td>
  </tr>
  <tr>
    <td>Personal data</td>
    <td>LWill personal data be processed for the proposed pilot? Personal data is understood as data that may directly or indirectly identify a natural person.</td>
  </tr>
</table> 

</p>
</div>
